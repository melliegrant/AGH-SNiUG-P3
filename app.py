import sys
import streamlit as st
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

import os
import tensorflow as tf
from tensorflow import keras
from tensorflow.keras import layers

st.title("ğŸ§ Projekt: Klasyfikacja pingwinÃ³w")

# === Krok 1: Åadowanie danych ===
st.header("1. Åadowanie danych")
st.markdown("""
Wczytywanie danych z pliku 
`data/penguins.csv`
""")

try:
    penguins = pd.read_csv("data/penguins.csv")
    st.success(f"âœ… ZaÅ‚adowano {len(penguins)} rekordÃ³w.")

    with st.expander("Pierwsze 5 wierszy"):
        st.dataframe(penguins.head())

except Exception as e:
    st.error(f"âŒ BÅ‚Ä…d Å‚adowania danych: {e}")
    st.stop()



# === Krok 2: Podstawowe informacje ===
st.header("2. Eksploracja danych")
st.markdown("""
Sprawdzono
- czy sÄ… braki (`NaN`),
- jakie sÄ… typy zmiennych (liczbowe vs kategoryczne),
- ile jest rekordÃ³w i klas.
""")

col1, col2 = st.columns(2)

with col1:
    st.subheader("BrakujÄ…ce wartoÅ›ci")
    missing = penguins.isnull().sum()
    st.write(missing)
    if missing.sum() > 0:
        st.warning(f"ÅÄ…cznie brakÃ³w: {missing.sum()}")

with col2:
    st.subheader("Liczba rekordÃ³w w klasach")
    species_counts = penguins['species'].value_counts()
    st.bar_chart(species_counts)
    st.write(species_counts)

st.subheader("Typy kolumn")
st.write(penguins.dtypes)
numeric_cols = penguins.select_dtypes(include=['number']).columns.tolist()
categorical_cols = penguins.select_dtypes(include=['object']).columns.tolist()
st.write(f"ğŸ”¢ Liczbowe: {numeric_cols}")
st.write(f"ğŸ”¤ Kategoryczne: {categorical_cols}")


# === Krok 3: Wizualizacja ===
# SÅ‚ownik. nazwa wyÅ›wietlana â†’ nazwa kolumny w danych
DISPLAY_TO_COLUMN = {
    "dÅ‚ug. dzioba (mm)": "bill_length_mm",
    "gÅ‚Ä™b. dzioba (mm)": "bill_depth_mm",
    "dÅ‚ug. pÅ‚etwy (mm)": "flipper_length_mm",
    "masa ciaÅ‚a (g)": "body_mass_g"
}

# Odwrotne mapowanie (dla podpisu osi)
COLUMN_TO_DISPLAY = {v: k for k, v in DISPLAY_TO_COLUMN.items()}

st.header("3. Jak gatunki siÄ™ rozrÃ³Å¼niajÄ…?")
st.markdown("""
Wybierz parÄ™ cech, by zobaczyÄ‡, czy gatunki tworzÄ… naturalne â€grupyâ€.
""")

# Usuwamy tylko braki w kluczowych kolumnach (dla wykresu)
plot_df = penguins.dropna(subset=list(DISPLAY_TO_COLUMN.values()))

x_label = st.selectbox("OÅ› X", list(DISPLAY_TO_COLUMN.keys()), index=2)  # domyÅ›lnie: dÅ‚ug. pÅ‚etwy
y_label = st.selectbox("OÅ› Y", list(DISPLAY_TO_COLUMN.keys()), index=0)  # domyÅ›lnie: dÅ‚ug. dzioba

# Konwersja na nazwy kolumn
x_col = DISPLAY_TO_COLUMN[x_label]
y_col = DISPLAY_TO_COLUMN[y_label]

# SprawdÅº, czy nie wybrano tej samej osi dwa razy
if x_col == y_col:
    st.warning("âš ï¸ OÅ› X i Y nie mogÄ… byÄ‡ tÄ… samÄ… cechÄ….")
else:
    fig, ax = plt.subplots(figsize=(6, 4))
    sns.scatterplot(data=plot_df, x=x_col, y=y_col, hue='species', palette='Set1', s=60, ax=ax)
    ax.set_xlabel(x_label)
    ax.set_ylabel(y_label)
    ax.set_title(f'{x_label} vs {y_label}')
    ax.legend(title="Gatunek")
    st.pyplot(fig)

    st.info(f"""
    **Interpretacja**
    - **Gentoo**: duÅ¼e wartoÅ›ci `{x_label}` i `{y_label}` - Å‚atwo odrÃ³Å¼niÄ‡.
    - **AdÃ©lie vs Chinstrap**: silne nakÅ‚adanie siÄ™ (szczegÃ³lnie w przestrzeni dziÃ³b: dÅ‚./gÅ‚Ä™b.) - klasyfikacja wymaga analizy wielu cech jednoczeÅ›nie.
    """)




# === Krok 4: Kodowanie kategoryczne ===
st.header("4. PrzeksztaÅ‚canie zmiennych kategorycznych")
st.markdown("""
Zmienne kategoryczne (`island`, `sex`) zostaÅ‚y przeksztaÅ‚cone metodÄ… kodowania typu **one-hot**, w ktÃ³rej kaÅ¼da kategoria reprezentowana jest przez oddzielnÄ… binarnÄ… zmiennÄ…. W celu ograniczenia multikolinearnoÅ›ci zastosowano opcjÄ™ drop='first', usuwajÄ…c jednÄ… kategoriÄ™ odniesienia dla kaÅ¼dej zmiennej. KaÅ¼da kategoria staje siÄ™ osobnÄ… kolumnÄ… (0/1).
""")

st.write("PrzykÅ‚ad dla `island`:")
example_island = pd.DataFrame({'island': ['Biscoe', 'Dream', 'Torgersen']})
encoded = pd.get_dummies(example_island, prefix='island')
st.dataframe(encoded)




# === Krok 5: Imputacja brakÃ³w ===
st.header("5. ObsÅ‚uga brakujÄ…cych wartoÅ›ci")
st.markdown("""            
BrakujÄ…ce wartoÅ›ci uzupeÅ‚niono, stosujÄ…c **imputacjÄ™**.
- dla danych liczbowych: **Å›rednia** (np. Å›rednia dÅ‚ugoÅ›Ä‡ dzioba),
- dla danych kategorycznych: **dominanta** (np. najczÄ™Å›ciej 'MALE'). 
""")

st.write("PrzykÅ‚ad braku w danych:")
st.dataframe(penguins[penguins.isnull().any(axis=1)].head(3))

st.write("Procedura zostaÅ‚a wykonana w pipelinie, co zapewnia brak wycieku danych.")


# 6. Przygotowanie X, y i podziaÅ‚ ===
st.header("6â€“7. Przygotowanie danych do modelu")

st.markdown("""
ZbiÃ³r podzielono na treningowy (80%) i testowy (20%) z zachowaniem proporcji klas (stratified split). Zmienna docelowa (species) zostaÅ‚a zakodowana numerycznie.

- **X** = cechy (dÅ‚ugoÅ›Ä‡ dzioba, pÅ‚etwy, wyspa, pÅ‚eÄ‡...)  
- **y** = cel (`species`)  
""")

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import LabelEncoder

# Przygotuj y
le = LabelEncoder()
y = le.fit_transform(penguins['species'])
X_raw = penguins.drop(columns=['species'])

st.write(f"âœ… y zakodowane: {dict(zip(le.classes_, range(len(le.classes_))))}")
st.write(f"âœ… X ma {X_raw.shape[0]} rekordÃ³w i {X_raw.shape[1]} kolumn.")

if st.button("Podziel dane **`80/20`**"):
    X_train, X_test, y_train, y_test = train_test_split(
        X_raw, y, test_size=0.2, random_state=42, stratify=y
    )
    st.session_state['X_train'] = X_train
    st.session_state['X_test'] = X_test
    st.session_state['y_train'] = y_train
    st.session_state['y_test'] = y_test
    st.session_state['le'] = le
    st.success(f"PodziaÅ‚ gotowy! Train: {len(X_train)}, Test: {len(X_test)}")




# === Krok 8â€“9: Modele klasyczne ===
st.header("8-9. Pierwsze modele â€” bez sieci neuronowych")
st.markdown("""
Do klasyfikacji zastosowano dwa algorytmy: **regresjÄ™ logistycznÄ…** oraz **drzewo decyzyjne**. Oceny dokonano na podstawie dokÅ‚adnoÅ›ci, F1-score oraz macierzy pomyÅ‚ek. 
""")

if 'X_train' not in st.session_state:
    st.warning("Najpierw podziel dane (Krok 7).")
else:
    from sklearn.preprocessing import StandardScaler, OneHotEncoder
    from sklearn.impute import SimpleImputer
    from sklearn.compose import ColumnTransformer
    from sklearn.pipeline import Pipeline
    from sklearn.linear_model import LogisticRegression
    from sklearn.tree import DecisionTreeClassifier
    from sklearn.metrics import accuracy_score, f1_score, confusion_matrix

    X_train = st.session_state['X_train']
    X_test = st.session_state['X_test']
    y_train = st.session_state['y_train']
    y_test = st.session_state['y_test']
    le = st.session_state['le']

    # Pipeline preprocessingu
    numeric_features = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']
    categorical_features = ['island', 'sex']

    numeric_pipe = Pipeline([
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler())
    ])
    categorical_pipe = Pipeline([
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))
    ])

    preprocessor = ColumnTransformer([
        ('num', numeric_pipe, numeric_features),
        ('cat', categorical_pipe, categorical_features)
    ])

    # Przetwarzamy X_train i X_test RAZ (dla wszystkich modeli, w tym NN)
    try:
        X_train_processed = preprocessor.fit_transform(X_train)
        X_test_processed = preprocessor.transform(X_test)

        # Skalujemy â€” ale tylko dla modeli wymagajÄ…cych skalowania (LogReg, NN)
        # W pipeline LogReg jest juÅ¼ scaler, ale dla NN chcemy mieÄ‡ czyste X_scaled
        # â†’ wiÄ™c wyciÄ…gamy tylko numeryczne cechy z pipeline i skalujemy je osobno?
        # âœ… Lepsze rozwiÄ…zanie: zmodyfikuj pipeline tak, by daÅ‚o siÄ™ uzyskaÄ‡ X_scaled
    except Exception as e:
        st.error(f"BÅ‚Ä…d preprocessingu: {e}")
        st.stop()

    # --- Helper: train & store results for a given model ---
    def train_and_store(model, model_key: str):
        model.fit(X_train, y_train)
        y_train_pred = model.predict(X_train)
        y_test_pred = model.predict(X_test)

        train_acc = accuracy_score(y_train, y_train_pred)
        test_acc = accuracy_score(y_test, y_test_pred)
        f1 = f1_score(y_test, y_test_pred, average='macro')
        cm = confusion_matrix(y_test, y_test_pred)
        cm_df = pd.DataFrame(cm, 
                            index=[f"Faktyczny: {cls}" for cls in le.classes_],
                            columns=[f"Pred: {cls}" for cls in le.classes_])

        # Store under unique key, e.g. 'model_1' or 'model_2'
        st.session_state[model_key] = {
            'model': model,
            'train_acc': train_acc,
            'test_acc': test_acc,
            'f1': f1,
            'cm_df': cm_df
        }

    st.subheader("Regresja logistyczna")

    if st.button("Wytrenuj model", key="train_model_1"):
        model1 = Pipeline([
            ('preprocessor', preprocessor),
            ('classifier', LogisticRegression(max_iter=1000, random_state=42))
        ])
        train_and_store(model1, 'model_1')

    # Display Model 1 results â€” if trained
    if 'model_1' in st.session_state:
        res = st.session_state['model_1']
        col1, col2, col3 = st.columns(3)
        col1.metric("Train Acc", f"{res['train_acc']:.2%}")
        col2.metric("Test Acc", f"{res['test_acc']:.2%}")
        col3.metric("F1 (macro)", f"{res['f1']:.2f}")

        st.write("Macierz pomyÅ‚ek (test):")
        st.dataframe(res['cm_df'])

        st.info("""
        ğŸ“Œ **Regresja logistyczna**
                
        OsiÄ…gniÄ™to bardzo dobrÄ… skutecznoÅ›Ä‡, co wskazuje na liniowÄ… separowalnoÅ›Ä‡ klas. **Macierz pomyÅ‚ek** nie zawiera Å¼adnych bÅ‚Ä™dÃ³w â€” zarÃ³wno w klasie minority (Chinstrap, n=14), jak i w pozostaÅ‚ych. 

        Wynik ten sugeruje, Å¼e dla danego zbioru liniowy decyzyjny hiperpÅ‚aszczyzna wystarcza do peÅ‚nej separacji, co jest zgodne z analizÄ… wizualnÄ… (Gentoo wyraÅºnie oddzielony, AdÃ©lie i Chinstrap â€” czÄ™Å›ciowo, ale wystarczajÄ…co).
        """)

    st.subheader("Drzewo decyzyjne")

    if st.button("Wytrenuj model", key="train_model_2"):
        # Drzewo â€” bez skalowania (niepotrzebne)
        preprocessor_no_scale = ColumnTransformer([
            ('num', SimpleImputer(strategy='mean'), numeric_features),
            ('cat', Pipeline([
                ('imputer', SimpleImputer(strategy='most_frequent')),
                ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))
            ]), categorical_features)
        ])
        model2 = Pipeline([
            ('preprocessor', preprocessor_no_scale),
            ('classifier', DecisionTreeClassifier(random_state=42, max_depth=5))
        ])
        train_and_store(model2, 'model_2')

    # Display Model 2 results â€” if trained
    if 'model_2' in st.session_state:
        res = st.session_state['model_2']
        col1, col2, col3 = st.columns(3)
        col1.metric("Train Acc", f"{res['train_acc']:.2%}")
        col2.metric("Test Acc", f"{res['test_acc']:.2%}")
        col3.metric("F1 (macro)", f"{res['f1']:.2f}")

        st.write("Macierz pomyÅ‚ek (test):")
        st.dataframe(res['cm_df'])

        st.info("""
        ğŸ“Œ **Drzewo decyzyjne**
                
        Z `max_depth=5` uzyskaÅ‚o nieco niÅ¼szÄ… skutecznoÅ›Ä‡ na teÅ›cie (98.55%), z 1 bÅ‚Ä™dem klasyfikacji (AdÃ©lie zaklasyfikowany jako Gentoo), co jest nieistotne statystycznie przy tak maÅ‚ym zbiorze testowym (n=69), ale pokazuje nieco wyÅ¼szÄ… wariancjÄ™ modelu.
        """)
    
    if st.button("ğŸ—‘ï¸ WyczyÅ›Ä‡ wyniki modeli"):
        st.session_state.pop('model_1', None)
        st.session_state.pop('model_2', None)
        st.rerun()





st.header("10. Skalowanie zmiennych")
st.info(f"âœ… Skalowanie (`StandardScaler`) zostaÅ‚o zastosowane w pipeline dla regresji logistycznej.")






# === TENSORFLOW ===


st.header("11. SieÄ‡ neuronowa (Keras/TensorFlow)")

st.markdown("""
Zbudowano *feedforward* sieÄ‡ neuronowÄ…:
- **Warstwa wejÅ›ciowa**: 8 neuronÃ³w (po preprocessingu),
- **Warstwy ukryte**: 16 â†’ 8 neuronÃ³w, aktywacja `ReLU`,
- **Warstwa wyjÅ›ciowa**: 3 neurony, aktywacja `softmax`.

Funkcja straty: `sparse_categorical_crossentropy`,  
Optymalizator: `Adam`, batch size: 16, epoki: 100.
""")

# ğŸ”‘ Przetwarzamy dane raz â€” wspÃ³lnie dla wszystkich modeli
if 'X_train_processed' not in st.session_state:
    if 'X_train' not in st.session_state:
        st.warning("âš ï¸ Najpierw podziel dane i wytrenuj modele klasyczne (Kroki 6â€“9).")
        st.stop()
    
    X_train = st.session_state['X_train']
    X_test = st.session_state['X_test']
    y_train = st.session_state['y_train']
    y_test = st.session_state['y_test']
    le = st.session_state['le']

    # Pipeline (jak wczeÅ›niej)
    numeric_features = ['bill_length_mm', 'bill_depth_mm', 'flipper_length_mm', 'body_mass_g']
    categorical_features = ['island', 'sex']

    numeric_pipe = Pipeline([
        ('imputer', SimpleImputer(strategy='mean')),
        ('scaler', StandardScaler())
    ])
    categorical_pipe = Pipeline([
        ('imputer', SimpleImputer(strategy='most_frequent')),
        ('encoder', OneHotEncoder(drop='first', handle_unknown='ignore'))
    ])
    preprocessor = ColumnTransformer([
        ('num', numeric_pipe, numeric_features),
        ('cat', categorical_pipe, categorical_features)
    ])

    # ğŸ”§ Przetwarzamy raz â€” zapisujemy do sesji
    X_train_processed = preprocessor.fit_transform(X_train)
    X_test_processed = preprocessor.transform(X_test)

    st.session_state['X_train_processed'] = X_train_processed
    st.session_state['X_test_processed'] = X_test_processed
    st.session_state['y_train'] = y_train
    st.session_state['y_test'] = y_test
    st.session_state['preprocessor'] = preprocessor
    st.session_state['le'] = le

    st.info("âœ… Dane przetworzone i zapisane do sesji.")

# !!!!! SprawdÅº, czy model juÅ¼ istnieje i moÅ¼na go wczytaÄ‡
if 'nn_model' not in st.session_state:
    model_path = "saved_models/penguin_nn.keras"
    if os.path.exists(model_path):
        try:
            st.session_state['nn_model'] = tf.keras.models.load_model(model_path)
            st.session_state['nn_loaded'] = True  # flaga â€” wczytany z pliku
            st.success("ğŸ§  ZaÅ‚adowano zapisany model sieci neuronowej.")
        except Exception as e:
            st.warning(f"âš ï¸ Nie udaÅ‚o siÄ™ wczytaÄ‡ modelu: {e}")

# ğŸ”˜ Trenowanie NN â€” tylko po naciÅ›niÄ™ciu
if st.button("Wytrenuj sieÄ‡ neuronowÄ…"):
    X_train_processed = st.session_state['X_train_processed']
    X_test_processed = st.session_state['X_test_processed']
    y_train = st.session_state['y_train']
    y_test = st.session_state['y_test']
    le = st.session_state['le']

    model = keras.Sequential([
        layers.Dense(16, activation='relu', input_shape=(X_train_processed.shape[1],)),
        layers.Dense(8, activation='relu'),
        layers.Dense(3, activation='softmax')  # 3 gatunki
    ])

    model.compile(
        optimizer='adam',
        loss='sparse_categorical_crossentropy',
        metrics=['accuracy']
    )

    early_stop = keras.callbacks.EarlyStopping(
        monitor='val_loss', patience=10, restore_best_weights=True, verbose=0
    )

    with st.spinner("ğŸ§  Trenowanie sieci neuronowej (moÅ¼e zajÄ…Ä‡ 5â€“10 sekund)..."):
        history = model.fit(
            X_train_processed, y_train,
            epochs=100,
            batch_size=16,
            validation_split=0.2,
            callbacks=[early_stop],
            verbose=0
        )

    # Zapisz
    st.session_state['nn_model'] = model
    st.session_state['nn_history'] = history.history

    # Ocena
    test_loss, test_acc = model.evaluate(X_test_processed, y_test, verbose=0)
    train_loss, train_acc = model.evaluate(X_train_processed, y_train, verbose=0)

    st.success("âœ… SieÄ‡ neuronowa wytrenowana!")
    col1, col2 = st.columns(2)
    col1.metric("Train Acc", f"{train_acc:.2%}")
    col2.metric("Test Acc", f"{test_acc:.2%}")

    # Krzywe uczenia
    fig, ax = plt.subplots(1, 2, figsize=(10, 3))
    hist = history.history
    epochs = range(1, len(hist['loss']) + 1)
    
    ax[0].plot(epochs, hist['accuracy'], 'b-', label='Train')
    ax[0].plot(epochs, hist['val_accuracy'], 'r--', label='Val')
    ax[0].set_title('Accuracy'); ax[0].legend()
    
    ax[1].plot(epochs, hist['loss'], 'b-', label='Train')
    ax[1].plot(epochs, hist['val_loss'], 'r--', label='Val')
    ax[1].set_title('Loss'); ax[1].legend()
    
    st.pyplot(fig)

    # Macierz pomyÅ‚ek
    y_pred = model.predict(X_test_processed)
    y_pred_classes = y_pred.argmax(axis=1)
    cm = confusion_matrix(y_test, y_pred_classes)
    cm_df = pd.DataFrame(cm,
                        index=[f"Faktyczny: {cls}" for cls in le.classes_],
                        columns=[f"Pred: {cls}" for cls in le.classes_])
    st.write("Macierz pomyÅ‚ek (test):")
    st.dataframe(cm_df)

    st.info("""
    ğŸ“Œ SieÄ‡ neuronowa osiÄ…gnÄ™Å‚a skutecznoÅ›Ä‡ zbliÅ¼onÄ… do modeli klasycznych (~98â€“100%), co potwierdza:  
    - dane sÄ… dobrze separowalne nawet prostymi modelami,  
    - zÅ‚oÅ¼onoÅ›Ä‡ sieci nie musi byÄ‡ duÅ¼a â€” 2 warstwy ukryte wystarczajÄ….  
    Brak rosnÄ…cego `val_loss` wskazuje na brak overfittingu.
    """)

    # !!!!! Zapisz model lokalnie
    os.makedirs("saved_models", exist_ok=True)
    model_save_path = "saved_models/penguin_nn.keras"
    try:
        # logi
        st.write("ğŸ” PrÃ³bujÄ™ zapisaÄ‡ modelâ€¦")
        os.makedirs("saved_models", exist_ok=True)
        model_save_path = "saved_models/penguin_nn.keras"
        st.write(f"ÅšcieÅ¼ka zapisu: {os.path.abspath(model_save_path)}")

        model.save(model_save_path)
        st.success(f"ğŸ’¾ Model zapisany lokalnie: `{model_save_path}`")
    except Exception as e:
        st.error(f"âŒ BÅ‚Ä…d zapisu modelu: {e}")
    
